---
layout: default
title: Zhenzhi Wang
picture: avater
---

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-156423478-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-156423478-1');
</script>

<div class="page-header">
  <div class="row">
    <div class="col-sm-12">
      <h3>Zhenzhi Wang</h3> <h5> Chinese Name: 王臻郅</h5>
    </div>
  </div>
  <div class="row">
    <div class="col-sm-6">
      <address>
        <a href="http://mcg.nju.edu.cn/en/index.html">MCG Lab</a><br/>
        <a href="https://ai.nju.edu.cn/">School of Artificial Intelligence</a><br/>
        <a href="https://www.nju.edu.cn/EN/">Nanjing University</a><br/>
      </address>
    </div>
    <div class="col-sm-4">
      <a href="mailto:zhenzhiwang@outlook.com"><span class="glyphicon glyphicon-envelope"></span></a> Email: zhenzhiwang [at] outlook.com<br/>
      <a href="tel:+86 133-9081-5189"><span class="glyphicon glyphicon-phone"></span></a> Call: +86 133-9081-5189<br/>
      <a href="https://github.com/zhenzhiwang">
        <img src="img/ico/github_icon.png" alt=""/>
      </a> Github: <a href="https://github.com/zhenzhiwang">zhenzhiwang</a>
    </div>
  </div>
</div>

<p>
<h4> About Me [<a href="pdfs/zhenzhiwang_CV.pdf" target="_blank"> CV </a>] [<a href="https://scholar.google.com/citations?hl=zh-CN&user=_sM6vPkAAAAJ">Google Scholar</a>] </h4>
</p>
<p>
I am currently a final-year Master student at <a href="http://mcg.nju.edu.cn/en/index.html">Multimedia Computing Group (MCG)</a>, <a href="https://www.nju.edu.cn/EN/">Nanjing University</a>, advised by <a href="http://wanglimin.github.io">Prof. Limin Wang</a>. 
Before that, I recieved my bachelor's degree from School of Physics, <a href="https://www.nju.edu.cn/EN/">Nanjing University</a> in 2019. 
</p>
<p>
My research area is computer vision and deep learning, with the focus on video understanding. Specifically, I have several research interests:
</p>
<b>Computer Vision</b>: action recognition, temporal action detection/segmentation
<br>
<b>Vision + Language</b>: temporal grounding, video + language pretraining


<h4>News</h4>
&bull; 09/2021 <a href="https://arxiv.org/abs/2109.04872">One paper</a> (1st author) released in arXiv about temporal grounding. <br>
&bull; 08/2021 One workshop paper accepted by ACM MM 2021 (1st author). It presented the overview of Tencent Multi-modal Ads Video Understanding Challenge. The 8-page extended version is available at <a href="http://arxiv.org/abs/2109.07951">here</a>. The <i>Tencent-AVS</i> dataset used in this challenge will be made publicly available soon at <a href="https://algo.qq.com/">here</a>.<br>
&bull; 07/2021 <a href="https://arxiv.org/abs/2105.07404">One paper</a> accepted by ICCV 2021 (4th-author). <br>
&bull; 06/2021 We got the 1st place in the <a href="http://www.picdataset.com/challenge/task/hcvg/">HC-STVG track of PIC Workshop</a> at CVPR 2021. As the 1st-author, I gave a 15-min oral presentation at this workshop to share our winner solution (in English).<br>
&bull; 04/2021 I was a track co-organizer of <a href="https://deeperaction.github.io/tracks/2-multisports/">DeeperAction Workshop</a> at ICCV 2021. <br>
&bull; 06/2020 <a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123700035.pdf">One paper</a> accepted by ECCV 2020 (1st-author). <br>


<h4>Experiences</h4>
&bull; Research Intern at Tencent (03/2021 - Present)<br>
&bull; <b>Reviewer</b> of IEEE TCSVT, Neurocomputing<br>

<h4>Contact</h4>
If you are interested in my research, e.g., details about my paper, interested in our dataset or just want to discuss research topics, please feel free to send me emails.
